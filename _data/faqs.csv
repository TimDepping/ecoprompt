question,answer
"Sind meine Daten sicher, wenn ich den Rechner nutze?","Ja, deine Eingaben bleiben lokal auf deinem Gerät und werden nicht ins Internet gesendet."
"Auf welches Modell beziehen sich die Berechnungen?","Die Berechnungen basieren auf dem Modell ChatGPT-4o, da dieses Modell zwischen Mai 2024 und August 2025 in der kostenlosen Version des Chatbots standardmäßig verfügbar war."
"Verbrauchen alle Modelle gleich viele Ressourcen?","Nein. Der Ressourcenverbrauch hängt stark von der Größe und Komplexität des Modells ab. Sowohl bei der Entwicklung (Training) als auch beim späteren Einsatz (Nutzung) unterscheiden sich die Werte deutlich.<br>Eine Studie aus dem Jahr 2025 liefert einen fundierten Überblick darüber, was unterschiedlich große Sprachmodelle (LLMs) im Durchschnitt an Strom, Wasser und CO₂ verbrauchen. <a href='#source-2'>[2]</a>"
"Ist der Energieaufwand für das Training des KI-Modells in meinen Ergebnissen enthalten?","Nein. Die angegebenen Werte beziehen sich ausschließlich auf die Rechenleistung, die bei der Beantwortung deiner Prompts entsteht. Der deutlich höhere Energieverbrauch, der beim Training des Modells anfällt, wurde nicht mit einberechnet."
"Wie viel Ressourcen hat das Training von Chat-GPT verbraucht?","Das Training großer Sprachmodelle (LLMs) ist extrem ressourcenintensiv.<br>Das gemeinnützige Electric Power Research Institute (EPRI) berechnete, dass es ca. 34 Tage und 1.287.00 kWh brauchte um das GPT-3 Modell zu trainieren und etwa 100 Tage und 62.318.800 kWh um das deutlich komplexere GPT-4 Modell zu trainieren. <a href='#source-4'>[4]</a> Der Stromverbrauch des Trainings ist also maßgeblich davon abhängig, wie komplex das jeweilige Modell ist. Dies lässt vermuten, dass das Training von Chat-GPT-5 nochmals weitaus mehr Strom beansprucht hat, als das Training von Chat-GPT-4.<br>Zum Einordnen: mit 62.000.000 kWh könnten rund 15.000 deutsche 4-Personen Haushalte für ein Jahr mit Strom versorgt werden oder ein gängiges E-Auto rund 10.000 mal um die Erde fahren.<br>Neben der Energie spielt auch der Wasserverbrauch eine wichtige Rolle. Während des energieintensiven Trainings werden große Mengen Wasser eingesetzt, um die Server zu kühlen und die Temperaturen stabil zu halten. So schätzten Forschende der University of California und der University of Texas, dass allein das Training von GPT-3 in Microsoft-Rechenzentren in den USA rund 5,4 Millionen Liter sauberes Süßwasser verbrauchte. Etwa 700.000 Liter davon waren direkt für die Kühlung notwendig, während der Rest in der Stromerzeugung und in der Lieferkette für die Herstellung der Server anfiel. <a href='#source-5'>[5]</a>"
"Was verbraucht Chat-GPT weltweit im Jahr?","Der weltweit laufende Betrieb von ChatGPT ist deutlich ressourcenintensiver als das Training. Laut dem gemeinnützigen Electric Power Research Institute (EPRI) entfallen im Durchschnitt etwa 60 % des gesamten Energieverbrauchs einer KI auf den täglichen Gebrauch, rund 30 % auf das Training und etwa 10 % auf die Modellentwicklung. <a href='#source-4'>[4]</a><br>Eine Studie aus 2025 gibt Berechnungen zum jährlichen Strom-, Wasserverbrauch einiger großen Sprachmodelle (LLMs) an, sowie zum Co2-Verbrauch. So berechneten sie, dass das GPT-4o Modell (das aktuellste Modell zum Veröffentlichungszeitpunkt der Studie) jährlich zwischen 391 und 463 Millionen kWh Strom verbraucht. Das entspricht ungefähr dem Jahresverbrauch einer Stadt mit 300.000 bis 400.000 Einwohnern, wie beispielsweise Münster oder Wuppertal. <a href='#source-2'>[2]</a><br>Neben dem Stromverbrauch verursacht der Betrieb auch einen hohen Wasserbedarf, da die Rechenzentren kontinuierlich gekühlt werden müssen. Für GPT-4o schätzt die Studie den weltweiten jährlichen Verbrauch auf 1,3 bis 1,6 Millionen Kiloliter sauberes Süßwasser. Das entspricht etwa 500 olympischen Schwimmbecken. Zudem verweisen die Forschenden darauf, dass dieses Wasser dauerhaft aus lokalen Ökosystemen entzogen wird und somit ein Äquivalent an Trinkwasser für 1,2 Millionen Menschen verbraucht werde. <a href='#source-2'>[2]</a><br>Auch die CO₂-Bilanz fällt erheblich aus, so legt die Studie dar, dass GPT-4o pro Jahr zwischen 138.000 und 163.000 Tonnen CO₂ verursacht. Das ist vergleichbar mit den Emissionen von etwa 2.300 Transatlantikflügen zwischen London und Boston. <a href='#source-2'>[2]</a>"
"Läuft Chat-GPT mit sauberem Strom?","Der Strom für ChatGPT stammt größtenteils aus dem US-Stromnetz, da die Server bisher von Microsoft betrieben werden. Microsoft hat zudem einen 20-Jahres-Vertrag mit einem Kernkraftunternehmen in Pennsylvania abgeschlossen, um Strom für seine Rechenzentren zu sichern. <a href='#source-6'>[6]</a> Da unklar ist, wie sich der Strommix von Microsoft konkret zusammensetzt beziehen wir uns hier auch auf den Strommix der gesamten USA zum angegebenen Zeitraum.<br>Im Jahr 2024/2025 setzte sich der US-Strommix etwa wie folgt zusammen: rund 58 % fossile Brennstoffe (40 % Gas und 16 % Kohle), etwa 24 % erneuerbare Energien (10 % Wind, 8 % Solar, 6 % Wasserkraft) und rund 17 % Kernkraft. <a href='#source-7'>[7]</a><br>Zum Vergleich: In Deutschland war der Strommix im gleichen Zeitraum deutlich sauberer. Etwa 26 % entfielen auf fossile Brennstoffe (8 % Gas, 18 % Kohle) und 72 % auf erneuerbare Energien (49 % Wind, 12 % Solar, 4 % Wasserkraft, 7 % Biomasse). <a href='#source-8'>[8]</a> <a href='#source-9'>[9]</a><br>Das bedeutet: Obwohl Microsoft teilweise erneuerbare Energien nutzt, stammt ein großer Teil des Stroms für ChatGPT aktuell vermutlich noch aus fossilen Quellen und Kernkraft, während der deutsche Strommix stärker auf saubere Energie setzt.<br>Hinweis: die USA produzieren (über) 100% ihres Stroms selbst, wohingegen Deutschland auch Strom importiert. <a href='#source-10'>[10]</a>"
"Auf welche Quellen beziehen sich die Angaben zum Verbrauch von ChatGPT und wie werden die Werte berechnet?","Die Angaben zum Energie- und Wasserverbrauch von ChatGPT stammen aus zwei Quellen.<br>Zum einen äußerte sich OpenAI-CEO Samuel Altman im Juni 2025 in einem Blogbeitrag erstmals zu konkreten Zahlen. Er nannte, dass eine ‚durchschnittliche Anfrage‘ etwa 0,34 Wattstunden Strom verbrauche. Das entspräche ungefähr dem Verbrauch eines Backofens in einer Sekunde oder einer hocheffizienten Glühbirne für ein paar Minuten. Der Wasserverbrauch einer solchen Anfrage läge laut Altman bei 0,00032176 Litern, also etwa einem Fünfzehntel eines Teelöffels. Es wurde dabei jedoch nicht öffentlich gemacht, wie diese Werte genau berechnet wurden und wie eine „durchschnittliche Anfrage“ definiert ist. <a href='#source-1'>[1]</a><br>Zum anderen stützten wir uns auf eine Studie aus dem Jahr 2025, die den Ressourcenverbrauch des aktuellsten Modells GPT-4o (zum Zeitpunkt der Veröffentlichung der Studie) untersucht hat. Hier wurde für eine typische mittellange Anfrage – definiert als 100 Wörter Input und 300 Wörter Output – ein Energieverbrauch von etwa 0,421 Wattstunden berechnet. In dieser Studie wurde erstmals klar definiert, was unter einem „mittellangen Prompt“ zu verstehen ist, wodurch die Werte vergleichbarer werden. <a href='#source-2'>[2]</a><br>Zum Vergleich: Für das Vorgängermodell GPT-4 lag der Wert bei etwa 1,978 Wattstunden und für die Reasoning-Modelle o3-mini und o4-mini zwischen 2,319 und 2,916 Wattstunden. <a href='#source-2'>[2]</a><br>Die gleiche Studie aus dem Jahr 2025 berechnet für das GPT-4o Modell, bei einer mittellangen Anfrage, einen Wasserverbrauch von ca. 1-2 ml. Wir rechnen deshalb mit einem Wert von 1,5 ml. <a href='#source-2'>[2]</a><br>Um den CO₂-Ausstoß von ChatGPT zu berechnen, kann man den durchschnittlichen CO₂-Wert pro verbrauchter Wattstunde Strom heranziehen. Laut der U.S. Energy Information Administration (EIA) werden in den USA etwa 0,367 Gramm CO₂ pro Wattstunde freigesetzt. <a href='#source-3'>[3]</a><br>Zum Vergleich: in Deutschland lag der Wert im gleichen Zeitraum bei rund 0,283 Gramm CO₂ pro Wattstunde, da der deutsche Strommix stärker auf erneuerbare Energien setzt. <a href='#source-11'>[11]</a>"
